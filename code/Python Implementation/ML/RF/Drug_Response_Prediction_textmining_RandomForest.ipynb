{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KljERxNzRmkW"
   },
   "source": [
    "## Download Data from Google-Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ec-A9EvvRel1",
    "outputId": "b68fc0aa-92a9-4814-f136-4b3e657cb109"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "File Name : Data\n",
    "File Link : https://drive.google.com/file/d/1rWS8Jj19ZOzdXFR4jUjmHIx_fTRyYzOw/view?usp=share_link\n",
    "File Id : '1rWS8Jj19ZOzdXFR4jUjmHIx_fTRyYzOw'\n",
    "\n",
    "'''\n",
    "!gdown --id 1rWS8Jj19ZOzdXFR4jUjmHIx_fTRyYzOw\n",
    "!unzip ccle_ctrpv2_gdse.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "e1fUeVyXTQDH"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error , mean_absolute_error\n",
    "from time import perf_counter, sleep\n",
    "import math\n",
    "import scipy.stats as stats\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BFFFwA9OTBdj"
   },
   "source": [
    "## Read train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "SfwaxDesUvIe"
   },
   "outputs": [],
   "source": [
    "# x_train\n",
    "ccle_ctrpv2 = pd.read_csv(\"../../data/ccle_ctrpv2_rnaseq_tpm.csv\")\n",
    "# x_test\n",
    "ccle_ctrpv2_aac = pd.read_csv(\"../../data/ccle_ctrpv2_aac.csv\")\n",
    "# y_train\n",
    "gdse_rnaseq = pd.read_csv(\"../../data/gdse_rnaseq_tpm.csv\")\n",
    "# y_test\n",
    "gdse_aac = pd.read_csv(\"../../data/gdse_aac.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Cleaning the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "2EDkuAA6oH5I"
   },
   "outputs": [],
   "source": [
    "drug_names = gdse_aac.columns.values.tolist()\n",
    "\n",
    "\n",
    "ccle_ctrpv2 = ccle_ctrpv2.rename(columns={\"Unnamed: 0\": \"sample\"})\n",
    "gdse_rnaseq = gdse_rnaseq.rename(columns={\"Unnamed: 0\": \"sample\"})\n",
    "ccle_ctrpv2_aac = ccle_ctrpv2_aac.rename(columns={\"Unnamed: 0\": \"sample\"})\n",
    "gdse_aac = gdse_aac.rename(columns={\"Unnamed: 0\": \"sample\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_names = drug_names[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nan(data):\n",
    "    data = data.dropna()\n",
    "    data.reset_index(drop = True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "for i in range(0, 40):\n",
    "    names.append(f'Column{i}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection method\n",
    "\n",
    "    textmining\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training procedure\n",
    "\n",
    "*For each drug in the drug list:*\n",
    "   1. Split the data in to train and test sets, and then remove the Nan values.\n",
    "   2. Merging X_train with ytrain, and X_test with  y_test because the samples in each are different.\n",
    "   3. Normalize the training X. </br>\n",
    "   \n",
    "   *Running the following 6 times:*\n",
    "   \n",
    "       4. Applying 4-fold Cross Valisation\n",
    "       5. Applying the relevant features selection technique, and extract the selected features.\n",
    "       6. Train the model based on the CV data and extracted features\n",
    "       7. Saving the best model performed in CV and the best features\n",
    "       \n",
    "   8. Predicting the test set using the best model from the previous section\n",
    "   9. Calculating the correlation score between the predicted drug_respons and the actual drug_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pearson_correlation 0.4242812467439225\n",
      "pearson_correlation 0.49244338313447433\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 79\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m     78\u001b[0m     best_model_index \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 79\u001b[0m     cv_scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkfold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mneg_mean_squared_error\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;66;03m# Calculate the mean squared error (MSE) scores\u001b[39;00m\n\u001b[0;32m     81\u001b[0m     mse_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mcv_scores\n",
      "File \u001b[1;32m~\\Anaconda\\envs\\[tensorflowversion]\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    513\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 515\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\Anaconda\\envs\\[tensorflowversion]\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:266\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    265\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 266\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda\\envs\\[tensorflowversion]\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda\\envs\\[tensorflowversion]\\lib\\site-packages\\joblib\\parallel.py:1061\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1058\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1060\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1061\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32m~\\Anaconda\\envs\\[tensorflowversion]\\lib\\site-packages\\joblib\\parallel.py:938\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    936\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    937\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 938\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    939\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    940\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32m~\\Anaconda\\envs\\[tensorflowversion]\\lib\\site-packages\\joblib\\_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    540\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda\\envs\\[tensorflowversion]\\lib\\concurrent\\futures\\_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m--> 453\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32m~\\Anaconda\\envs\\[tensorflowversion]\\lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pearson_corr = []\n",
    "kendalltau_corr = []\n",
    "spearmanr_corr = []\n",
    "MSE_metric = []\n",
    "RMSE_metric = []\n",
    "MAE_metric = []\n",
    "pearson_corr_train = []\n",
    "kendalltau_corr_train = []\n",
    "spearmanr_corr_train = []\n",
    "MSE_metric_train = []\n",
    "RMSE_metric_train = []\n",
    "MAE_metric_train = []\n",
    "Sscaler = StandardScaler()\n",
    "start = perf_counter()\n",
    "\n",
    "for idx, drug in enumerate(drug_names):\n",
    "    \n",
    "    selected_features = []\n",
    "\n",
    "\n",
    "    '''\n",
    "        train test split\n",
    "    '''\n",
    "    y_train = ccle_ctrpv2_aac[['sample', drug]]\n",
    "    y_test  = gdse_aac[['sample', drug]]\n",
    "\n",
    "    y_train = remove_nan(y_train)\n",
    "    y_test  = remove_nan(y_test)\n",
    "\n",
    "    ccle_ctrpv2 = remove_nan(ccle_ctrpv2)\n",
    "    gdse_rnaseq = remove_nan(gdse_rnaseq)\n",
    "\n",
    "\n",
    "    '''\n",
    "\n",
    "    Merge\n",
    "    '''\n",
    "\n",
    "    gdse_rnaseq_merged_df = pd.merge(gdse_rnaseq, y_test, on='sample', how='inner')\n",
    "    ccle_ctrpv2_merged_df = pd.merge(ccle_ctrpv2, y_train, on='sample', how='inner')\n",
    "\n",
    "    X_train = ccle_ctrpv2_merged_df.iloc[:, 1: len(gdse_rnaseq.columns)]\n",
    "    X_test  = gdse_rnaseq_merged_df.iloc[:, 1: len(gdse_rnaseq.columns)]\n",
    "\n",
    "    Y_train = ccle_ctrpv2_merged_df.iloc[:, len(gdse_rnaseq.columns):]\n",
    "    Y_test  = gdse_rnaseq_merged_df.iloc[:, len(gdse_rnaseq.columns):]\n",
    "\n",
    "    X_train_norm = Sscaler.fit_transform(X_train)\n",
    "    X_train_normalized = pd.DataFrame(X_train_norm, columns=X_train.columns)\n",
    "\n",
    "    X_test_norm = Sscaler.fit_transform(X_test)\n",
    "    X_test_normalized = pd.DataFrame(X_test_norm, columns=X_test.columns)\n",
    "\n",
    "    X = np.asarray(X_train_normalized)\n",
    "    X_test_array = np.asarray(X_test_normalized)\n",
    "    Y = np.asarray(Y_train).ravel()\n",
    "    Y_test_array = np.asarray(Y_test).ravel()\n",
    "    \n",
    "\n",
    "    estimators = RandomForestRegressor(max_depth= 2 , n_estimators=20)\n",
    "\n",
    "    # Define the number of folds for cross-validation\n",
    "    num_folds = 4\n",
    "\n",
    "    # Create a K-fold cross-validation object\n",
    "    kfold = KFold(n_splits=num_folds)\n",
    "    dict = {\n",
    "      \"mse_scores\": [],\n",
    "      \"model_index\": []\n",
    "    }\n",
    "    \n",
    "\n",
    "    estimators.fit(X, Y)\n",
    "\n",
    "    \n",
    "    # Perform cross-validation\n",
    "\n",
    "    best_model_index = []\n",
    "    cv_scores = cross_val_score(estimators, X, Y , cv=kfold, scoring='neg_mean_squared_error' , n_jobs=-1)\n",
    "    # Calculate the mean squared error (MSE) scores\n",
    "    mse_scores = -cv_scores\n",
    "    # Get the best model based on cross-validation\n",
    "    mymin = np.min(mse_scores)\n",
    "\n",
    "\n",
    "    best_model_index = [i for i, x in enumerate(mse_scores) if x == mymin]\n",
    "    dict['mse_scores'].append(mymin)\n",
    "    dict['model_index'].append(best_model_index)\n",
    "        \n",
    "        # Retrieve the best model based on the index\n",
    "    indx = dict['mse_scores'].index(min(dict['mse_scores']))\n",
    "    best_model = estimators.estimators_[indx]\n",
    "\n",
    "\n",
    "    text_mining_drug = pd.read_csv(\"../../text_mining_feature/\" + drug + \".csv\",  names = names)\n",
    "    text_mining_drug = text_mining_drug.tail(-1)\n",
    "    \n",
    "    new_features = text_mining_drug['Column3']\n",
    "    \n",
    "    merge_features = [item for item in np.asarray(new_features) if item in X_train_normalized.columns]\n",
    "    X_split, X_val, Y_split, y_val = train_test_split(np.asarray(X_train_normalized[merge_features]), Y_train, test_size=0.25, random_state=1)\n",
    "    \n",
    "    best_model.fit(X_split,  Y_split)\n",
    "    predictions_train = best_model.predict(X_val)\n",
    "\n",
    "    mse_train = mean_squared_error(np.asarray(y_val).ravel(), predictions_train)\n",
    "    rmse_train = math.sqrt(mse_train)\n",
    "    mae_train = mean_absolute_error(np.asarray(y_val).ravel(), predictions_train)\n",
    "\n",
    "    # Calculate Correlation for the validation data\n",
    "    spearmanr_correlation_train, _ = stats.spearmanr(np.asarray(y_val).ravel(), predictions_train)\n",
    "    kendalltau_correlation_train, _ = stats.kendalltau(np.asarray(y_val).ravel(), predictions_train)\n",
    "    pearson_correlation_train, _ = pearsonr(np.asarray(y_val).ravel(), predictions_train)\n",
    "\n",
    "\n",
    "    pearson_corr_train.append(pearson_correlation_train)\n",
    "    kendalltau_corr_train.append(kendalltau_correlation_train)\n",
    "    spearmanr_corr_train.append(spearmanr_correlation_train)\n",
    "    MSE_metric_train.append(mse_train)\n",
    "    RMSE_metric_train.append(rmse_train)\n",
    "    MAE_metric_train.append(mae_train)\n",
    "    \n",
    "    #Predict X test\n",
    "    predictions = best_model.predict(np.asarray(X_test_normalized[merge_features]))\n",
    "    \n",
    "    #Calculating Metrics for the Testing Phase\n",
    "    mse = mean_squared_error(Y_test_array, predictions)\n",
    "    rmse = math.sqrt(mse)\n",
    "    mae = mean_absolute_error(Y_test_array, predictions)\n",
    "    \n",
    "    #Calculating Correlation for the Testing Phase\n",
    "    \n",
    "    spearmanr_correlation, _ = stats.spearmanr(Y_test_array.flatten(),  predictions.flatten())\n",
    "    kendalltau_correlation, _ = stats.kendalltau(Y_test_array.flatten(),  predictions.flatten())\n",
    "    pearson_correlation, _ = pearsonr(Y_test_array.flatten(),  predictions.flatten())\n",
    "    print(\"pearson_correlation\" , pearson_correlation)\n",
    "    pearson_corr.append(pearson_correlation)\n",
    "    kendalltau_corr.append(kendalltau_correlation)\n",
    "    spearmanr_corr.append(spearmanr_correlation)\n",
    "    MSE_metric.append(mse)\n",
    "    RMSE_metric.append(rmse)\n",
    "    MAE_metric.append(mae)\n",
    "    \n",
    "end = perf_counter()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution_time = end - start\n",
    "\n",
    "df = pd.DataFrame({\"Drugs\": drug_names, \"pearsonCor\": pearson_corr , \"spearmanCor\": spearmanr_corr , \"kendallCor\": kendalltau_corr , \n",
    "                  \"RMSE\": RMSE_metric ,  \"MSE\": MSE_metric , \"MAE\": MAE_metric , \"Time\": execution_time})\n",
    "df.to_csv('RF-results/Result_textmining_RandomForrest_test.csv', index=False)\n",
    "\n",
    "df = pd.DataFrame({\"Drugs\": drug_names, \"pearsonCor\": pearson_corr_train , \"spearmanCor\": spearmanr_corr_train , \"kendallCor\": kendalltau_corr_train , \n",
    "                  \"RMSE\": RMSE_metric_train ,  \"MSE\": MSE_metric_train , \"MAE\": MAE_metric_train , \"Time\": execution_time})\n",
    "df.to_csv('RF-results/Result_textmining_RandomForrest_train.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
