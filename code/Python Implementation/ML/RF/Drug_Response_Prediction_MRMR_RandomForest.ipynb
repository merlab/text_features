{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KljERxNzRmkW"
   },
   "source": [
    "## Download Data from Google-Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ec-A9EvvRel1",
    "outputId": "b68fc0aa-92a9-4814-f136-4b3e657cb109"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "File Name : Data\n",
    "File Link : https://drive.google.com/file/d/1rWS8Jj19ZOzdXFR4jUjmHIx_fTRyYzOw/view?usp=share_link\n",
    "File Id : '1rWS8Jj19ZOzdXFR4jUjmHIx_fTRyYzOw'\n",
    "\n",
    "'''\n",
    "!gdown --id 1rWS8Jj19ZOzdXFR4jUjmHIx_fTRyYzOw\n",
    "!unzip ccle_ctrpv2_gdse.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "e1fUeVyXTQDH"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from genetic_selection import GeneticSelectionCV\n",
    "from sklearn.metrics import mean_squared_error , mean_absolute_error\n",
    "from time import perf_counter, sleep\n",
    "import math\n",
    "import scipy.stats as stats\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BFFFwA9OTBdj"
   },
   "source": [
    "## Read train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "SfwaxDesUvIe"
   },
   "outputs": [],
   "source": [
    "# x_train\n",
    "ccle_ctrpv2 = pd.read_csv(\"../../data/ccle_ctrpv2_rnaseq_tpm.csv\")\n",
    "# x_test\n",
    "ccle_ctrpv2_aac = pd.read_csv(\"../../data/ccle_ctrpv2_aac.csv\")\n",
    "# y_train\n",
    "gdse_rnaseq = pd.read_csv(\"../../data/gdse_rnaseq_tpm.csv\")\n",
    "# y_test\n",
    "gdse_aac = pd.read_csv(\"../../data/gdse_aac.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Cleaning the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "2EDkuAA6oH5I"
   },
   "outputs": [],
   "source": [
    "drug_names = gdse_aac.columns.values.tolist()\n",
    "\n",
    "\n",
    "ccle_ctrpv2 = ccle_ctrpv2.rename(columns={\"Unnamed: 0\": \"sample\"})\n",
    "gdse_rnaseq = gdse_rnaseq.rename(columns={\"Unnamed: 0\": \"sample\"})\n",
    "ccle_ctrpv2_aac = ccle_ctrpv2_aac.rename(columns={\"Unnamed: 0\": \"sample\"})\n",
    "gdse_aac = gdse_aac.rename(columns={\"Unnamed: 0\": \"sample\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_names = drug_names[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nan(data):\n",
    "    data = data.dropna()\n",
    "    data.reset_index(drop = True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection method\n",
    "\n",
    "    MRMR (Minimum-Redundancy-Maximum-Relevance) \n",
    "    \n",
    "**Install**:     `!pip install mrmr_selection`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mrmr\n",
    "from mrmr import mrmr_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training procedure\n",
    "\n",
    "*For each drug in the drug list:*\n",
    "   1. Split the data in to train and test sets, and then remove the Nan values.\n",
    "   2. Merging X_train with ytrain, and X_test with  y_test because the samples in each are different.\n",
    "   3. Normalize the training X. </br>\n",
    "   \n",
    "   *Running the following 6 times:*\n",
    "   \n",
    "       4. Applying 4-fold Cross Valisation\n",
    "       5. Applying the relevant features selection technique, and extract the selected features.\n",
    "       6. Train the model based on the CV data and extracted features\n",
    "       7. Saving the best model performed in CV and the best features\n",
    "       \n",
    "   8. Predicting the test set using the best model from the previous section\n",
    "   9. Calculating the correlation score between the predicted drug_respons and the actual drug_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:50<00:00,  1.71s/it]\n",
      "100%|██████████| 100/100 [02:53<00:00,  1.73s/it]\n",
      "100%|██████████| 100/100 [02:45<00:00,  1.65s/it]\n",
      "100%|██████████| 100/100 [02:45<00:00,  1.66s/it]\n",
      "100%|██████████| 100/100 [02:23<00:00,  1.44s/it]\n",
      "100%|██████████| 100/100 [02:51<00:00,  1.72s/it]\n",
      "100%|██████████| 100/100 [02:45<00:00,  1.65s/it]\n",
      "100%|██████████| 100/100 [02:51<00:00,  1.71s/it]\n",
      "100%|██████████| 100/100 [02:48<00:00,  1.69s/it]\n",
      "100%|██████████| 100/100 [02:48<00:00,  1.68s/it]\n",
      "100%|██████████| 100/100 [02:47<00:00,  1.68s/it]\n",
      "100%|██████████| 100/100 [02:47<00:00,  1.67s/it]\n",
      "100%|██████████| 100/100 [02:45<00:00,  1.66s/it]\n",
      "100%|██████████| 100/100 [02:46<00:00,  1.66s/it]\n",
      "100%|██████████| 100/100 [02:48<00:00,  1.68s/it]\n",
      "100%|██████████| 100/100 [02:47<00:00,  1.68s/it]\n",
      "100%|██████████| 100/100 [03:13<00:00,  1.94s/it]\n",
      "100%|██████████| 100/100 [03:41<00:00,  2.21s/it]\n",
      "100%|██████████| 100/100 [03:38<00:00,  2.19s/it]\n",
      "100%|██████████| 100/100 [03:38<00:00,  2.19s/it]\n",
      "100%|██████████| 100/100 [03:38<00:00,  2.18s/it]\n",
      "100%|██████████| 100/100 [03:36<00:00,  2.17s/it]\n",
      "100%|██████████| 100/100 [03:37<00:00,  2.18s/it]\n",
      "100%|██████████| 100/100 [03:38<00:00,  2.19s/it]\n",
      "100%|██████████| 100/100 [03:39<00:00,  2.19s/it]\n",
      "100%|██████████| 100/100 [03:39<00:00,  2.20s/it]\n",
      "100%|██████████| 100/100 [06:07<00:00,  3.68s/it]\n",
      "100%|██████████| 100/100 [06:22<00:00,  3.82s/it]\n",
      "100%|██████████| 100/100 [21:38<00:00, 12.99s/it]  \n",
      "100%|██████████| 100/100 [02:46<00:00,  1.67s/it]\n",
      "100%|██████████| 100/100 [02:41<00:00,  1.62s/it]\n",
      "100%|██████████| 100/100 [02:46<00:00,  1.66s/it]\n",
      "100%|██████████| 100/100 [02:45<00:00,  1.66s/it]\n",
      "100%|██████████| 100/100 [02:46<00:00,  1.66s/it]\n",
      "100%|██████████| 100/100 [02:41<00:00,  1.62s/it]\n",
      "100%|██████████| 100/100 [02:45<00:00,  1.66s/it]\n",
      "100%|██████████| 100/100 [02:45<00:00,  1.65s/it]\n",
      "100%|██████████| 100/100 [02:46<00:00,  1.66s/it]\n"
     ]
    }
   ],
   "source": [
    "pearson_corr = []\n",
    "kendalltau_corr = []\n",
    "spearmanr_corr = []\n",
    "MSE_metric = []\n",
    "RMSE_metric = []\n",
    "MAE_metric = []\n",
    "pearson_corr_train = []\n",
    "kendalltau_corr_train = []\n",
    "spearmanr_corr_train = []\n",
    "MSE_metric_train = []\n",
    "RMSE_metric_train = []\n",
    "MAE_metric_train = []\n",
    "Sscaler = StandardScaler()\n",
    "start = perf_counter()\n",
    "\n",
    "for idx, drug in enumerate(drug_names):\n",
    "    \n",
    "    selected_features = []\n",
    "\n",
    "\n",
    "    '''\n",
    "        train test split\n",
    "    '''\n",
    "    y_train = ccle_ctrpv2_aac[['sample', drug]]\n",
    "    y_test  = gdse_aac[['sample', drug]]\n",
    "\n",
    "    y_train = remove_nan(y_train)\n",
    "    y_test  = remove_nan(y_test)\n",
    "\n",
    "    ccle_ctrpv2 = remove_nan(ccle_ctrpv2)\n",
    "    gdse_rnaseq = remove_nan(gdse_rnaseq)\n",
    "\n",
    "\n",
    "    '''\n",
    "\n",
    "    Merge\n",
    "    '''\n",
    "\n",
    "    gdse_rnaseq_merged_df = pd.merge(gdse_rnaseq, y_test, on='sample', how='inner')\n",
    "    ccle_ctrpv2_merged_df = pd.merge(ccle_ctrpv2, y_train, on='sample', how='inner')\n",
    "\n",
    "    X_train = ccle_ctrpv2_merged_df.iloc[:, 1: len(gdse_rnaseq.columns)]\n",
    "    X_test  = gdse_rnaseq_merged_df.iloc[:, 1: len(gdse_rnaseq.columns)]\n",
    "\n",
    "    Y_train = ccle_ctrpv2_merged_df.iloc[:, len(gdse_rnaseq.columns):]\n",
    "    Y_test  = gdse_rnaseq_merged_df.iloc[:, len(gdse_rnaseq.columns):]\n",
    "\n",
    "    X_train_norm = Sscaler.fit_transform(X_train)\n",
    "    X_train_normalized = pd.DataFrame(X_train_norm, columns=X_train.columns)\n",
    "\n",
    "    X_test_norm = Sscaler.fit_transform(X_test)\n",
    "    X_test_normalized = pd.DataFrame(X_test_norm, columns=X_test.columns)\n",
    "\n",
    "    X = np.asarray(X_train_normalized)\n",
    "    X_test_array = np.asarray(X_test_normalized)\n",
    "    Y = np.asarray(Y_train).ravel()\n",
    "    Y_test_array = np.asarray(Y_test).ravel()\n",
    "    \n",
    "\n",
    "    estimators = RandomForestRegressor(max_depth= 2 , n_estimators=20)\n",
    "\n",
    "    # Define the number of folds for cross-validation\n",
    "    num_folds = 4\n",
    "\n",
    "    # Create a K-fold cross-validation object\n",
    "    kfold = KFold(n_splits=num_folds)\n",
    "\n",
    "    \n",
    "    estimators.fit(X, Y)\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    cv_scores = cross_val_score(estimators, X, Y , cv=kfold, scoring='neg_mean_squared_error' , n_jobs=-1)\n",
    "\n",
    "    # Calculate the mean squared error (MSE) scores\n",
    "    mse_scores = -cv_scores\n",
    "    # Get the best model based on cross-validation\n",
    "    mymin = np.min(mse_scores)\n",
    "    best_model_index = [i for i, x in enumerate(mse_scores) if x == mymin]\n",
    "    #best_model_index = np.argmax(mse_scores)\n",
    "    best_model = estimators\n",
    "    # Retrieve the best model based on the index\n",
    "    best_model = best_model.estimators_[best_model_index.pop()]\n",
    "\n",
    "\n",
    "    selected_features = mrmr.mrmr_regression(X_train_normalized, Y_train , 100)\n",
    "    X_train_new = X_train_normalized[selected_features]\n",
    "    X_split, X_val, Y_split, y_val = train_test_split(X_train_new, Y_train, test_size=0.25, random_state=1)\n",
    "    best_model.fit(X_split, Y_split)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    predictions_train = best_model.predict(X_val)\n",
    "\n",
    "    mse_train = mean_squared_error(np.asarray(y_val).ravel(), predictions_train)\n",
    "    rmse_train = math.sqrt(mse_train)\n",
    "    mae_train = mean_absolute_error(np.asarray(y_val).ravel(), predictions_train)\n",
    "\n",
    "    # Calculate Correlation for the validation data\n",
    "    spearmanr_correlation_train, _ = stats.spearmanr(np.asarray(y_val).ravel(), predictions_train)\n",
    "    kendalltau_correlation_train, _ = stats.kendalltau(np.asarray(y_val).ravel(), predictions_train)\n",
    "    pearson_correlation_train, _ = pearsonr(np.asarray(y_val).ravel(), predictions_train)\n",
    "\n",
    "\n",
    "    pearson_corr_train.append(pearson_correlation_train)\n",
    "    kendalltau_corr_train.append(kendalltau_correlation_train)\n",
    "    spearmanr_corr_train.append(spearmanr_correlation_train)\n",
    "    MSE_metric_train.append(mse_train)\n",
    "    RMSE_metric_train.append(rmse_train)\n",
    "    MAE_metric_train.append(mae_train)\n",
    "    \n",
    "    #Predict X test\n",
    "    X_test_new = X_test_normalized[selected_features]\n",
    "    predictions = best_model.predict(np.asarray(X_test_new))\n",
    "    \n",
    "    #Calculating Metrics for the Testing Phase\n",
    "    mse = mean_squared_error(Y_test_array, predictions)\n",
    "    rmse = math.sqrt(mse)\n",
    "    mae = mean_absolute_error(Y_test_array, predictions)\n",
    "    \n",
    "    #Calculating Correlation for the Testing Phase\n",
    "    \n",
    "    spearmanr_correlation, _ = stats.spearmanr(Y_test_array.flatten(),  predictions.flatten())\n",
    "    kendalltau_correlation, _ = stats.kendalltau(Y_test_array.flatten(),  predictions.flatten())\n",
    "    pearson_correlation, _ = pearsonr(Y_test_array.flatten(),  predictions.flatten())\n",
    "    \n",
    "    pearson_corr.append(pearson_correlation)\n",
    "    kendalltau_corr.append(kendalltau_correlation)\n",
    "    spearmanr_corr.append(spearmanr_correlation)\n",
    "    MSE_metric.append(mse)\n",
    "    RMSE_metric.append(rmse)\n",
    "    MAE_metric.append(mae)\n",
    "    \n",
    "end = perf_counter()    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution_time = end - start\n",
    "\n",
    "df = pd.DataFrame({\"Drugs\": drug_names, \"pearsonCor\": pearson_corr , \"spearmanCor\": spearmanr_corr , \"kendallCor\": kendalltau_corr , \n",
    "                  \"RMSE\": RMSE_metric ,  \"MSE\": MSE_metric , \"MAE\": MAE_metric , \"Time\": execution_time})\n",
    "df.to_csv('RF-results/Result_MRMR_RandomForrest_test.csv', index=False)\n",
    "\n",
    "df = pd.DataFrame({\"Drugs\": drug_names, \"pearsonCor\": pearson_corr_train , \"spearmanCor\": spearmanr_corr_train , \"kendallCor\": kendalltau_corr_train , \n",
    "                  \"RMSE\": RMSE_metric_train ,  \"MSE\": MSE_metric_train , \"MAE\": MAE_metric_train , \"Time\": execution_time})\n",
    "df.to_csv('RF-results/Result_MRMR_RandomForrest_train.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
